import pandas as pd
from datetime import timedelta
from wordcloud import WordCloud
import matplotlib.pyplot as plt

def filter_posts_by_keywords(posts_df: pd.DataFrame,
                             include_keywords: list[str] = None,
                             exclude_keywords: list[str] = None,
                             text_col: str = "content") -> pd.DataFrame:
    """
    Return only those posts that contain at least one of the include_keywords
    (if provided) and none of the exclude_keywords (if provided).
    """
    df = posts_df.copy()
    if include_keywords:
        pattern = "|".join([fr"\b{kw}\b" for kw in include_keywords])
        df = df[df[text_col].str.contains(pattern, case=False, na=False)]
    if exclude_keywords:
        pattern = "|".join([fr"\b{kw}\b" for kw in exclude_keywords])
        df = df[~df[text_col].str.contains(pattern, case=False, na=False)]
    return df

def filter_posts_by_user_attributes(posts_df: pd.DataFrame,
                                    users_df: pd.DataFrame,
                                    attrs: dict,
                                    user_id_col: str = "user_id") -> pd.DataFrame:
    """
    Join posts to users on user_id_col and keep only posts where user attributes
    match all key/value pairs in attrs (e.g., {"gender":"F", "region":"West"}).
    """
    df = posts_df.merge(users_df, how="left", on=user_id_col)
    for key, val in attrs.items():
        df = df[df[key] == val]
    return df.drop(columns=users_df.columns.difference([user_id_col]))

def compute_trending_posts(posts_df: pd.DataFrame,
                           time_col: str = "timestamp",
                           engagement_col: str = "engagement",
                           window: timedelta = timedelta(days=1),
                           top_n: int = 50) -> pd.DataFrame:
    """
    Identify the top_n posts gaining engagement at the greatest rate.
    We compute engagement growth over the last two windows and rank by difference.
    """
    df = posts_df.copy()
    df[time_col] = pd.to_datetime(df[time_col])
    now = df[time_col].max()
    # Define two time windows
    recent_start = now - window
    prev_start = now - 2*window

    # Sum engagement in each window per post
    recent = (df[df[time_col] >= recent_start]
              .groupby("post_id")[engagement_col]
              .sum()
              .rename("recent_eng"))
    prev = (df[(df[time_col] >= prev_start) & (df[time_col] < recent_start)]
            .groupby("post_id")[engagement_col]
            .sum()
            .rename("prev_eng"))

    trend = (recent.to_frame()
             .join(prev, how="left")
             .fillna(0))
    trend["growth"] = trend["recent_eng"] - trend["prev_eng"]

    # Return top_n trending post IDs with their growth
    top = trend.sort_values("growth", ascending=False).head(top_n)
    return top.reset_index()

def generate_word_cloud(posts_df: pd.DataFrame,
                        text_col: str = "content",
                        max_words: int = 100,
                        figsize: tuple[int,int] = (10, 6)) -> None:
    """
    Generate and display a word cloud from the given posts' text.
    """
    text = " ".join(posts_df[text_col].dropna().tolist())
    wc = WordCloud(width=800, height=400, max_words=max_words,
                   background_color="white").generate(text)
    plt.figure(figsize=figsize)
    plt.imshow(wc, interpolation="bilinear")
    plt.axis("off")
    plt.show()

# Example usage:
if __name__ == "__main__":
    # Load your data
    posts = pd.read_csv("posts.csv")       # expects columns: post_id, user_id, content, timestamp, engagement
    users = pd.read_csv("users.csv")       # expects columns: user_id, age, gender, region, etc.

    # 1. Filter by keywords
    filtered = filter_posts_by_keywords(posts,
                                        include_keywords=["profanity1", "profanity2"],
                                        exclude_keywords=["spam", "ad"])

    # 2. Filter by user attributes
    filtered = filter_posts_by_user_attributes(filtered,
                                               users,
                                               attrs={"region": "North America", "gender": "F"})

    # 3. Compute trending posts
    trending = compute_trending_posts(filtered,
                                      time_col="timestamp",
                                      engagement_col="engagement",
                                      window=timedelta(days=1),
                                      top_n=50)

    # 4. Subset original posts to trending ones
    top_posts = posts[posts["post_id"].isin(trending["post_id"])]

    # 5. Generate word cloud for trending posts
    generate_word_cloud(top_posts, text_col="content", max_words=100)
